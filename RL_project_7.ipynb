{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "meNNqqqlRlN4"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'line_profiler'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-24-23677d9f5755>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0mdevice\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'cuda'\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_available\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m'cpu'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m \u001B[0mget_ipython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_line_magic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'load_ext'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'line_profiler'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001B[0m in \u001B[0;36mrun_line_magic\u001B[0;34m(self, magic_name, line, _stack_depth)\u001B[0m\n\u001B[1;32m   2325\u001B[0m                 \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'local_ns'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_local_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstack_depth\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2326\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuiltin_trap\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2327\u001B[0;31m                 \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2328\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2329\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<decorator-gen-57>\u001B[0m in \u001B[0;36mload_ext\u001B[0;34m(self, module_str)\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.9/site-packages/IPython/core/magic.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(f, *a, **k)\u001B[0m\n\u001B[1;32m    185\u001B[0m     \u001B[0;31m# but it's overkill for just that one bit of state.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    186\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mmagic_deco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 187\u001B[0;31m         \u001B[0mcall\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mlambda\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    188\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    189\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcallable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.9/site-packages/IPython/core/magics/extension.py\u001B[0m in \u001B[0;36mload_ext\u001B[0;34m(self, module_str)\u001B[0m\n\u001B[1;32m     31\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mmodule_str\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mUsageError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Missing module name.'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 33\u001B[0;31m         \u001B[0mres\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshell\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextension_manager\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_extension\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodule_str\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     34\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     35\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mres\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'already loaded'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.9/site-packages/IPython/core/extensions.py\u001B[0m in \u001B[0;36mload_extension\u001B[0;34m(self, module_str)\u001B[0m\n\u001B[1;32m     78\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mmodule_str\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0msys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodules\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     79\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mprepended_to_syspath\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mipython_extension_dir\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 80\u001B[0;31m                     \u001B[0mmod\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimport_module\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodule_str\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     81\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0mmod\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__file__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstartswith\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mipython_extension_dir\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     82\u001B[0m                         print((\"Loading extensions from {dir} is deprecated. \"\n",
      "\u001B[0;32m/usr/lib/python3.9/importlib/__init__.py\u001B[0m in \u001B[0;36mimport_module\u001B[0;34m(name, package)\u001B[0m\n\u001B[1;32m    125\u001B[0m                 \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    126\u001B[0m             \u001B[0mlevel\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 127\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_bootstrap\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_gcd_import\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mlevel\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpackage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    128\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    129\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.9/importlib/_bootstrap.py\u001B[0m in \u001B[0;36m_gcd_import\u001B[0;34m(name, package, level)\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.9/importlib/_bootstrap.py\u001B[0m in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.9/importlib/_bootstrap.py\u001B[0m in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'line_profiler'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from sympy.utilities.iterables import subsets\n",
    "from sympy.utilities.iterables import multiset_permutations\n",
    "from scipy.special import comb\n",
    "import pandas as pd\n",
    "import gym\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_almost_align(board, s):\n",
    "    size = board.shape[0]\n",
    "    for irow in range(size):\n",
    "        if board[irow, :].sum() == s * (size - 1):\n",
    "            i_empty = np.where(board[irow, :] == 0)[0].item()\n",
    "            return (irow, i_empty)\n",
    "    for icol in range(size):\n",
    "        if board[:, icol].sum() == s * (size - 1):\n",
    "            i_empty = np.where(board[:, icol] == 0)[0].item()\n",
    "            return (i_empty, icol)\n",
    "    if np.diag(board).sum() == s * (size - 1):\n",
    "        i_empty = np.where(np.diag(board) == 0)[0].item()\n",
    "        return (i_empty, i_empty)\n",
    "    if np.diag(np.rot90(board)).sum() == s * (size - 1):\n",
    "        for i in range(size):\n",
    "            if board[i, size - 1 - i] == 0:\n",
    "                return (i, size - 1 - i)\n",
    "    return None\n",
    "\n",
    "def random_policy(board, symbol):\n",
    "    available_pos = np.array(np.where(game.board == 0)).T\n",
    "    pos = np.random.randint(available_pos.shape[0])\n",
    "    return tuple(available_pos[np.random.randint(available_pos.shape[0])])\n",
    "\n",
    "def linear_policy(board, symbol):\n",
    "    available_pos = np.array(np.where(game.board == 0)).T\n",
    "    return tuple(available_pos[0])\n",
    "\n",
    "def advanced_static_policy(board, symbol):\n",
    "    coords = check_almost_align(board, symbol)\n",
    "    if coords is not None:\n",
    "        return coords\n",
    "    coords = check_almost_align(board, -symbol)\n",
    "    if coords is not None:\n",
    "        return coords\n",
    "    available_pos = np.array(np.where(game.board == 0)).T\n",
    "    return tuple(available_pos[0])\n",
    "\n",
    "def advanced_random_policy(board, symbol):\n",
    "    coords = check_almost_align(board, symbol)\n",
    "    if coords is not None:\n",
    "        return coords\n",
    "    coords = check_almost_align(board, -symbol)\n",
    "    if coords is not None:\n",
    "        return coords\n",
    "    available_pos = np.array(np.where(game.board == 0)).T\n",
    "    return tuple(available_pos[np.random.randint(available_pos.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_Wavup5eRlOB"
   },
   "outputs": [],
   "source": [
    "def sarsa(game, agent, opponent_policy, alpha, alpha_factor, gamma, epsilon, epsilon_factor, \\\n",
    "          r_win, r_lose, r_even, r_even2, num_episodes):\n",
    "    for episode_index in range(num_episodes):\n",
    "        if episode_index % 1000 == 0:\n",
    "            print('.', end='')\n",
    "        alpha *= alpha_factor\n",
    "        epsilon *= epsilon_factor\n",
    "        state = game.reset()\n",
    "        if episode_index%2 == 1:\n",
    "            action = opponent_policy(state, game.turn)\n",
    "            state, _, _, _ = game.step(action)\n",
    "        action = agent.epsilon_greedy_policy(state, epsilon)\n",
    "        state_history = [state.copy()]\n",
    "        action_history = [action]\n",
    "        while True:\n",
    "            ################### The agent ignores this happens UNLESS it ends the game\n",
    "            intermediate_state, reward, done, _ = game.step(action)\n",
    "            if done:\n",
    "                if reward > 0:\n",
    "                    final_reward = r_win\n",
    "                else:\n",
    "                    final_reward = r_even\n",
    "                break\n",
    "            intermediate_action = opponent_policy(intermediate_state, game.turn)\n",
    "            ################### ------------------------------------------------\n",
    "            state, reward, done, _ = game.step(intermediate_action)\n",
    "            if done:\n",
    "                if reward > 0:\n",
    "                    reward = r_lose\n",
    "                else:\n",
    "                    reward = r_even2\n",
    "                break\n",
    "            action = agent.epsilon_greedy_policy(state, epsilon)\n",
    "            state_history.append(state.copy())\n",
    "            action_history.append(action)\n",
    "            \n",
    "        agent.update_Qtable(state_history, action_history, reward, alpha, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "yi4p1W_wRlOC"
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, size=3, policy=None):\n",
    "        self.q_array = pd.DataFrame(columns=[str(i)+str(j) for i in range(size) for j in range(size)])\n",
    "        self.policy = policy\n",
    "        self.identity = {}\n",
    "        self.convert_rot90_1 = {}\n",
    "        self.convert_rot90_2 = {}\n",
    "        self.convert_rot90_3 = {}\n",
    "        self.convert_horizontal_axis = {}\n",
    "        self.convert_vertical_axis = {}\n",
    "        self.convert_diag = {}\n",
    "        self.convert_antidiag = {}\n",
    "        empty = np.zeros([size]*2, dtype=int)\n",
    "        \n",
    "        for i in range(empty.shape[0]):\n",
    "            for j in range(empty.shape[0]):\n",
    "                empty *= 0\n",
    "                empty[i, j] = 1\n",
    "                tr_empty = empty\n",
    "                coords_transform = tuple(np.argwhere(tr_empty == 1)[0])\n",
    "                self.identity[str(i)+str(j)] = coords_transform\n",
    "        \n",
    "        for i in range(empty.shape[0]):\n",
    "            for j in range(empty.shape[0]):\n",
    "                empty *= 0\n",
    "                empty[i, j] = 1\n",
    "                tr_empty = np.rot90(empty, 1)\n",
    "                coords_transform = tuple(np.argwhere(tr_empty == 1)[0])\n",
    "                self.convert_rot90_1[str(i)+str(j)] = coords_transform\n",
    "        \n",
    "        for i in range(empty.shape[0]):\n",
    "            for j in range(empty.shape[0]):\n",
    "                empty *= 0\n",
    "                empty[i, j] = 1\n",
    "                tr_empty = np.rot90(empty, 2)\n",
    "                coords_transform = tuple(np.argwhere(tr_empty == 1)[0])\n",
    "                self.convert_rot90_2[str(i)+str(j)] = coords_transform\n",
    "                \n",
    "        for i in range(empty.shape[0]):\n",
    "            for j in range(empty.shape[0]):\n",
    "                empty *= 0\n",
    "                empty[i, j] = 1\n",
    "                tr_empty = np.rot90(empty, 3)\n",
    "                coords_transform = tuple(np.argwhere(tr_empty == 1)[0])\n",
    "                self.convert_rot90_3[str(i)+str(j)] = coords_transform\n",
    "                \n",
    "        for i in range(empty.shape[0]):\n",
    "            for j in range(empty.shape[0]):\n",
    "                empty *= 0\n",
    "                empty[i, j] = 1\n",
    "                tr_empty = empty[::-1]\n",
    "                coords_transform = tuple(np.argwhere(tr_empty == 1)[0])\n",
    "                self.convert_horizontal_axis[str(i)+str(j)] = coords_transform\n",
    "        \n",
    "        for i in range(empty.shape[0]):\n",
    "            for j in range(empty.shape[0]):\n",
    "                empty *= 0\n",
    "                empty[i, j] = 1\n",
    "                tr_empty = empty[:, ::-1]\n",
    "                coords_transform = tuple(np.argwhere(tr_empty == 1)[0])\n",
    "                self.convert_vertical_axis[str(i)+str(j)] = coords_transform\n",
    "        \n",
    "        for i in range(empty.shape[0]):\n",
    "            for j in range(empty.shape[0]):\n",
    "                empty *= 0\n",
    "                empty[i, j] = 1\n",
    "                tr_empty = empty.T\n",
    "                coords_transform = tuple(np.argwhere(tr_empty == 1)[0])\n",
    "                self.convert_diag[str(i)+str(j)] = coords_transform\n",
    "                \n",
    "        for i in range(empty.shape[0]):\n",
    "            for j in range(empty.shape[0]):\n",
    "                empty *= 0\n",
    "                empty[i, j] = 1\n",
    "                tr_empty = np.rot90(empty, 2).T\n",
    "                coords_transform = tuple(np.argwhere(tr_empty == 1)[0])\n",
    "                self.convert_antidiag[str(i)+str(j)] = coords_transform\n",
    "                \n",
    "    \n",
    "    def update_Qtable(self, state_history, action_history, reward, alpha, gamma): \n",
    "        code_last_state, code_last_action = self.encode_state_and_action(state_history[-1], action_history[-1])\n",
    "        try:\n",
    "            self.q_array.loc[code_last_state]\n",
    "        except:\n",
    "            self.q_array.loc[code_last_state] = 0.5\n",
    "        self.q_array.loc[code_last_state, code_last_action] = reward\n",
    "        \n",
    "        for i in range(len(state_history)-2, -1, -1):\n",
    "            state = state_history[i]\n",
    "            new_state = state_history[i+1]\n",
    "            action = action_history[i]\n",
    "            new_action = action_history[i+1]\n",
    "            code_state, code_action = self.encode_state_and_action(state, action)\n",
    "            try:\n",
    "                self.q_array.loc[code_state]\n",
    "            except:\n",
    "                self.q_array.loc[code_state] = 0.5\n",
    "            code_new_state, code_new_action = self.encode_state_and_action(new_state, new_action)\n",
    "            self.q_array.loc[code_state, code_action] = (1 - alpha) * self.q_array.loc[code_state, code_action] \\\n",
    "                                                        + alpha * gamma * self.q_array.loc[code_new_state, code_new_action]\n",
    "    \n",
    "    def play_vs_opponent(self, state, symbol):\n",
    "        if self.policy is not None:\n",
    "            return self.policy(state, symbol)\n",
    "        state_code = self.encode_state(state)\n",
    "        try:\n",
    "            self.q_array.loc[state_code]\n",
    "        except:\n",
    "            legal_moves = np.argwhere(state == 0)\n",
    "            return tuple(legal_moves[np.random.randint(legal_moves.shape[0])])\n",
    "        ###### Find best move\n",
    "        potential_actions = self.q_array.loc[state_code]\n",
    "        reference_state = self.decode_one_state(state_code)\n",
    "        free_spots_scores = []\n",
    "        \n",
    "        if np.prod(state == reference_state):\n",
    "            for a in potential_actions.index:\n",
    "                tr_coords = self.identity[a]\n",
    "                if state[tr_coords] == 0:\n",
    "                    free_spots_scores.append((tr_coords, potential_actions.loc[a]))\n",
    "        \n",
    "        elif np.prod(state == np.rot90(reference_state, 1)):\n",
    "            for a in potential_actions.index:\n",
    "                tr_coords = self.convert_rot90_1[a]\n",
    "                if state[tr_coords] == 0:\n",
    "                    free_spots_scores.append((tr_coords, potential_actions.loc[a]))\n",
    "        \n",
    "        elif np.prod(state == np.rot90(reference_state, 2)):\n",
    "            for a in potential_actions.index:\n",
    "                tr_coords = self.convert_rot90_2[a]\n",
    "                if state[tr_coords] == 0:\n",
    "                    free_spots_scores.append((tr_coords, potential_actions.loc[a]))\n",
    "        \n",
    "        elif np.prod(state == np.rot90(reference_state, 3)):\n",
    "            for a in potential_actions.index:\n",
    "                tr_coords = self.convert_rot90_3[a]\n",
    "                if state[tr_coords] == 0:\n",
    "                    free_spots_scores.append((tr_coords, potential_actions.loc[a]))\n",
    "        \n",
    "        elif np.prod(state == reference_state[::-1]):\n",
    "            for a in potential_actions.index:\n",
    "                tr_coords = self.convert_horizontal_axis[a]\n",
    "                if state[tr_coords] == 0:\n",
    "                    free_spots_scores.append((tr_coords, potential_actions.loc[a]))\n",
    "        \n",
    "        elif np.prod(state == reference_state[:, ::-1]):\n",
    "            for a in potential_actions.index:\n",
    "                tr_coords = self.convert_vertical_axis[a]\n",
    "                if state[tr_coords] == 0:\n",
    "                    free_spots_scores.append((tr_coords, potential_actions.loc[a]))\n",
    "        \n",
    "        elif np.prod(state == reference_state.T):\n",
    "            for a in potential_actions.index:\n",
    "                tr_coords = self.convert_diag[a]\n",
    "                if state[tr_coords] == 0:\n",
    "                    free_spots_scores.append((tr_coords, potential_actions.loc[a]))\n",
    "        \n",
    "        elif np.prod(state == np.rot90(reference_state, 2).T):\n",
    "            for a in potential_actions.index:\n",
    "                tr_coords = self.convert_antidiag[a]\n",
    "                if state[tr_coords] == 0:\n",
    "                    free_spots_scores.append((tr_coords, potential_actions.loc[a]))\n",
    "        else:\n",
    "            print('Error in play_vs_opponent in Agent !!!')\n",
    "        max_reward = max(free_spots_scores, key=lambda x: x[1])[1]\n",
    "        best_actions = [act for act, rew in free_spots_scores if rew == max_reward]\n",
    "        return best_actions[np.random.randint(len(best_actions))]\n",
    "        \n",
    "    def greedy_policy(self, state):\n",
    "        \"\"\"\n",
    "        Return the next action as a tuple\n",
    "        \"\"\"\n",
    "        code_state = self.encode_state(state)\n",
    "        try:\n",
    "            self.q_array.loc[code_state]\n",
    "        except:\n",
    "            self.q_array.loc[code_state] = 0.5\n",
    "        reference_state = self.decode_one_state(code_state)\n",
    "        legal_actions = []\n",
    "        actions = self.q_array.loc[code_state]\n",
    "            \n",
    "        if np.prod(state == reference_state):\n",
    "            for act in actions.index:\n",
    "                coords_transform = self.identity[act]\n",
    "                if state[coords_transform] == 0:\n",
    "                    legal_actions.append((coords_transform, actions.loc[act]))\n",
    "            max_reward = max(legal_actions, key=lambda x: x[1])[1]\n",
    "            best_actions = [act_rew[0] for act_rew in legal_actions if act_rew[1] == max_reward]\n",
    "            return best_actions[np.random.randint(len(best_actions))]\n",
    "        \n",
    "        if np.prod(state == np.rot90(reference_state, 1)):\n",
    "            for act in actions.index:\n",
    "                coords_transform = self.convert_rot90_1[act]\n",
    "                if state[coords_transform] == 0:\n",
    "                    legal_actions.append((coords_transform, actions.loc[act]))\n",
    "            max_reward = max(legal_actions, key=lambda x: x[1])[1]\n",
    "            best_actions = [act_rew[0] for act_rew in legal_actions if act_rew[1] == max_reward]\n",
    "            return best_actions[np.random.randint(len(best_actions))]\n",
    "        \n",
    "        if np.prod(state == np.rot90(reference_state, 2)):\n",
    "            for act in actions.index:\n",
    "                coords_transform = self.convert_rot90_2[act]\n",
    "                if state[coords_transform] == 0:\n",
    "                    legal_actions.append((coords_transform, actions.loc[act]))\n",
    "            max_reward = max(legal_actions, key=lambda x: x[1])[1]\n",
    "            best_actions = [act_rew[0] for act_rew in legal_actions if act_rew[1] == max_reward]\n",
    "            return best_actions[np.random.randint(len(best_actions))]\n",
    "        \n",
    "        if np.prod(state == np.rot90(reference_state, 3)):\n",
    "            for act in actions.index:\n",
    "                coords_transform = self.convert_rot90_3[act]\n",
    "                if state[coords_transform] == 0:\n",
    "                    legal_actions.append((coords_transform, actions.loc[act]))\n",
    "            max_reward = max(legal_actions, key=lambda x: x[1])[1]\n",
    "            best_actions = [act_rew[0] for act_rew in legal_actions if act_rew[1] == max_reward]\n",
    "            return best_actions[np.random.randint(len(best_actions))]\n",
    "        \n",
    "        if np.prod(state == reference_state[::-1]):\n",
    "            for act in actions.index:\n",
    "                coords_transform = self.convert_horizontal_axis[act]\n",
    "                if state[coords_transform] == 0:\n",
    "                    legal_actions.append((coords_transform, actions.loc[act]))\n",
    "            max_reward = max(legal_actions, key=lambda x: x[1])[1]\n",
    "            best_actions = [act_rew[0] for act_rew in legal_actions if act_rew[1] == max_reward]\n",
    "            return best_actions[np.random.randint(len(best_actions))]\n",
    "        \n",
    "        if np.prod(state == reference_state[:, ::-1]):\n",
    "            for act in actions.index:\n",
    "                coords_transform = self.convert_vertical_axis[act]\n",
    "                if state[coords_transform] == 0:\n",
    "                    legal_actions.append((coords_transform, actions.loc[act]))\n",
    "            max_reward = max(legal_actions, key=lambda x: x[1])[1]\n",
    "            best_actions = [act_rew[0] for act_rew in legal_actions if act_rew[1] == max_reward]\n",
    "            return best_actions[np.random.randint(len(best_actions))]\n",
    "        \n",
    "        if np.prod(state == reference_state.T):\n",
    "            for act in actions.index:\n",
    "                coords_transform = self.convert_diag[act]\n",
    "                if state[coords_transform] == 0:\n",
    "                    legal_actions.append((coords_transform, actions.loc[act]))\n",
    "            max_reward = max(legal_actions, key=lambda x: x[1])[1]\n",
    "            best_actions = [act_rew[0] for act_rew in legal_actions if act_rew[1] == max_reward]\n",
    "            return best_actions[np.random.randint(len(best_actions))]\n",
    "        \n",
    "        if np.prod(state == np.rot90(reference_state, 2).T):\n",
    "            for act in actions.index:\n",
    "                coords_transform = self.convert_antidiag[act]\n",
    "                if state[coords_transform] == 0:\n",
    "                    legal_actions.append((coords_transform, actions.loc[act]))\n",
    "            max_reward = max(legal_actions, key=lambda x: x[1])[1]\n",
    "            best_actions = [act_rew[0] for act_rew in legal_actions if act_rew[1] == max_reward]\n",
    "            return best_actions[np.random.randint(len(best_actions))]\n",
    "        print('\\nError in greedy policy !!!\\n')\n",
    "        print(state, '\\n')\n",
    "        print(reference_state, '\\n')\n",
    "        print(reference_state[::-1][::-1].T)\n",
    "\n",
    "    def epsilon_greedy_policy(self, state, epsilon):\n",
    "        \"\"\"\n",
    "        Return the next action as a tuple\n",
    "        \"\"\"\n",
    "        if self.q_array.empty or np.random.rand() < epsilon:\n",
    "            legal_moves = np.argwhere(state == 0)\n",
    "            size = legal_moves.shape[0]\n",
    "            random_idx = np.random.randint(size)\n",
    "            action = tuple(legal_moves[random_idx])\n",
    "        else:\n",
    "            action = self.greedy_policy(state)\n",
    "        return action\n",
    "    \n",
    "    def encode_action(self, action):\n",
    "        if type(action) is str:\n",
    "            return action\n",
    "        code_action = ''\n",
    "        for i in action:\n",
    "            code_action += str(i)\n",
    "        return code_action\n",
    "\n",
    "    def decode_action(self, code_action):\n",
    "        return tuple([int(i) for i in code_action])\n",
    "\n",
    "    def encode_one_state(self, state):\n",
    "        code_state = ''\n",
    "        for i in state.flatten():\n",
    "            code_state += str(i) if i != -1 else '2'\n",
    "        return code_state\n",
    "\n",
    "    def generate_all_sym_states(self, state):\n",
    "        sym_states = [self.encode_one_state(state), self.encode_one_state(np.rot90(state, 1)), \\\n",
    "                      self.encode_one_state(np.rot90(state, 2)), self.encode_one_state(np.rot90(state, 3)), \\\n",
    "                      self.encode_one_state(state[::-1]), self.encode_one_state(state[:, ::-1]), \\\n",
    "                      self.encode_one_state(state.T), self.encode_one_state(np.rot90(state, 2).T)]\n",
    "        sym_states.sort()\n",
    "        return sym_states\n",
    "    \n",
    "    def encode_state_and_action(self, state, action):\n",
    "        empty_state = state * 0\n",
    "        empty_state[action] = 1\n",
    "        sym = [(self.encode_one_state(state), tuple(np.argwhere(empty_state == 1)[0])), \\\n",
    "               (self.encode_one_state(np.rot90(state, 1)), tuple(np.argwhere(np.rot90(empty_state, 1) == 1)[0])), \\\n",
    "               (self.encode_one_state(np.rot90(state, 2)), tuple(np.argwhere(np.rot90(empty_state, 2) == 1)[0])), \\\n",
    "               (self.encode_one_state(np.rot90(state, 3)), tuple(np.argwhere(np.rot90(empty_state, 3) == 1)[0])), \\\n",
    "               (self.encode_one_state(state[::-1]), tuple(np.argwhere(empty_state[::-1] == 1)[0])), \\\n",
    "               (self.encode_one_state(state[:, ::-1]), tuple(np.argwhere(empty_state[:, ::-1] == 1)[0])), \\\n",
    "               (self.encode_one_state(state.T), tuple(np.argwhere(empty_state.T == 1)[0])), \\\n",
    "               (self.encode_one_state(np.rot90(state, 2).T), tuple(np.argwhere(np.rot90(empty_state, 2).T == 1)[0]))]\n",
    "        sym.sort(key=lambda x: x[0])\n",
    "        code_state = sym[0][0]\n",
    "        tr_action = sym[0][1]\n",
    "        code_action = self.encode_action(tr_action)\n",
    "        return code_state, code_action\n",
    "\n",
    "    def encode_state(self, state):\n",
    "        sym_states = self.generate_all_sym_states(state)\n",
    "        return sym_states[0]\n",
    "    \n",
    "    def decode_one_state(self, code_state):\n",
    "        flat_list = [0 if elem == '0' else 1 if elem == '1' else -1 for elem in list(code_state)]\n",
    "        size = int(np.sqrt(len(code_state)))\n",
    "        state = np.reshape(flat_list, (size, size))\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "LhVXcQs8RlOD"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "class Game(gym.Env):\n",
    "    \n",
    "    def __init__(self, p1, p2, size=3, n_dim=2):\n",
    "        assert(type(n_dim) is int and n_dim >= 2), \"wrong n_dim\"\n",
    "        assert(type(size) is int and size >= 2), \"wrong size\"\n",
    "        self.n_dim = n_dim\n",
    "        self.size = size\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "        self.turn = 1\n",
    "        self.board = np.zeros([size]*n_dim, dtype=int)\n",
    "        self.current_score = (0, 0)\n",
    "        self._max_episode_steps = 1000\n",
    "        super(Game, self).__init__()\n",
    "    \n",
    "    def simulate_games(self, n=100):\n",
    "        win_p1, win_p2, tot_even = 0, 0, 0\n",
    "        for _ in range(n // 2):\n",
    "            s1, s2 = self.play_a_game(verbose=False)\n",
    "            if s1 > s2:\n",
    "                win_p1 += 1\n",
    "            elif s2 > s1:\n",
    "                win_p2 += 1\n",
    "            else:\n",
    "                tot_even += 1\n",
    "        self.p1, self.p2 = self.p2, self.p1\n",
    "        for _ in range(n // 2):\n",
    "            s1, s2 = self.play_a_game(verbose=False)\n",
    "            if s1 > s2:\n",
    "                win_p2 += 1\n",
    "            elif s2 > s1:\n",
    "                win_p1 += 1\n",
    "            else:\n",
    "                tot_even += 1\n",
    "        self.p1, self.p2 = self.p2, self.p1\n",
    "        return win_p1, win_p2, tot_even\n",
    "    \n",
    "    def play_a_game(self, verbose=True):\n",
    "        self.reset()\n",
    "        if verbose:\n",
    "            self.render()\n",
    "        digits = '1234567890'\n",
    "        while not self.is_done():\n",
    "            if self.turn == 1:\n",
    "                player = self.p1\n",
    "            else:\n",
    "                player = self.p2\n",
    "            if isinstance(player, Agent):\n",
    "                coords = player.play_vs_opponent(self.board, self.turn)\n",
    "                if verbose:\n",
    "                    print('Agent plays :', coords, '\\n')\n",
    "            else:\n",
    "                coords_str = input('Coordinates of next move : ')\n",
    "                print()\n",
    "                coords = []\n",
    "                for c in coords_str:\n",
    "                    if c in digits:\n",
    "                        coords.append(int(c))\n",
    "                coords = tuple(coords)\n",
    "                while len(coords) != self.n_dim or max(coords) >= self.size or not self.is_available(coords):\n",
    "                    coords_str = input('Position not available, please try another one : ')\n",
    "                    coords = []\n",
    "                    for c in coords_str:\n",
    "                        if c in digits:\n",
    "                            coords.append(int(c))\n",
    "                    coords = tuple(coords)\n",
    "            self.step(coords)\n",
    "            if verbose:\n",
    "                self.render()\n",
    "        if verbose:\n",
    "            print('Game over. Score :', self.current_score)\n",
    "            if self.current_score[0] > self.current_score[1]:\n",
    "                print(self.p1, 'wins !')\n",
    "            elif self.current_score[1] > self.current_score[0]:\n",
    "                print(self.p2, 'wins !')\n",
    "            else:\n",
    "                print('Even score.')\n",
    "        return self.current_score\n",
    "    \n",
    "    def is_available(self, position):\n",
    "        return self.board[position] == 0\n",
    "    \n",
    "    def is_done(self):\n",
    "        if self.n_dim == 2:\n",
    "            return sum(self.current_score) != 0 or 0 not in self.board\n",
    "        return 0 not in self.board\n",
    "    \n",
    "    def reset(self):\n",
    "        self.turn = 1\n",
    "        self.current_score = (0, 0)\n",
    "        self.board *= 0\n",
    "        return self.board.copy()\n",
    "\n",
    "    def step(self, position):\n",
    "        self.board[position] = self.turn\n",
    "        score_p1, score_p2 = self.score()\n",
    "        score_p1_diff, score_p2_diff =  score_p1 - self.current_score[0], score_p2 - self.current_score[1]\n",
    "        # update only the score of the player that did the latest move\n",
    "        if self.turn == 1:\n",
    "            self.current_score = (score_p1, self.current_score[1])\n",
    "        else:\n",
    "            self.current_score = (self.current_score[0], score_p2)\n",
    "        reward = score_p1_diff if self.turn == 1 else score_p2_diff\n",
    "        self.turn *= -1\n",
    "        return self.board, reward, self.is_done(), None             \n",
    "    \n",
    "    def render(self):\n",
    "        visual_board = self.board.copy()\n",
    "        visual_board = np.where(visual_board == -1, 'O', visual_board)\n",
    "        visual_board = np.where(visual_board == '1', 'X', visual_board)\n",
    "        visual_board = np.where(visual_board == '0', '.', visual_board)\n",
    "        for icol in range(self.size):\n",
    "            for row in visual_board[icol, :]:\n",
    "                print(row, end=' ')\n",
    "            print()\n",
    "        print()\n",
    "    \n",
    "    def score(self):\n",
    "        score_p1 = 0\n",
    "        score_p2 = 0\n",
    "        \n",
    "        def slice_to_mask(L):\n",
    "            \"\"\"\n",
    "            Enables to use slicing operator like array[x, y, :, z] with choosing the position\n",
    "            of the symbol ':' (represented with a -1 instead). For example L can be equal to\n",
    "            [0, 0, -1, 0] if we want to access self.board[0, 0, :, 0]\n",
    "            \"\"\"\n",
    "            mask = np.zeros([self.size] * self.n_dim, dtype=bool)\n",
    "            dim = L.index(-1)\n",
    "            for tile in range(self.size):\n",
    "                L[dim] = tile\n",
    "                mask[tuple(L)] = True\n",
    "            return mask\n",
    "        \n",
    "        # vertical and horizontal axis\n",
    "        all_axis = []\n",
    "        for d in range(self.size ** self.n_dim):\n",
    "            all_axis.append([(d // self.size**k) % self.size for k in range(self.n_dim)[::-1]])\n",
    "            # example in 3D case with size 3 :\n",
    "            # all_axis = [ [i, j, k] for i = 0, 1, 2 for j = 0, 1, 2 for k = 0, 1, 2 ]\n",
    "        for d in range(self.n_dim):\n",
    "            d_axis = np.array(all_axis)\n",
    "            d_axis[:, d] = -1\n",
    "            d_axis = np.unique(d_axis, axis=0)\n",
    "            for axis in d_axis:\n",
    "                space_mask = slice_to_mask(list(axis))\n",
    "                in_game_axis = self.board[space_mask]\n",
    "                axis_value = in_game_axis.sum().item()\n",
    "                if axis_value == self.size:\n",
    "                    score_p1 += 1\n",
    "                elif axis_value == -self.size:\n",
    "                    score_p2 += 1\n",
    "        \n",
    "        # diagonal axis\n",
    "        diag = np.array([range(self.size)]).T\n",
    "        antidiag = np.array([range(self.size-1, -1, -1)]).T\n",
    "        poss_diag = np.array([diag, antidiag])\n",
    "        poss_index = list(range(self.size))\n",
    "        coords_to_check = set()\n",
    "        for dof in range(self.n_dim-2, -1, -1):\n",
    "            dof_fc = self.n_dim - dof\n",
    "            cpt = 0\n",
    "            for fc in subsets(poss_diag, dof_fc, repetition=True):\n",
    "                if cpt == int(dof_fc / 2) + 1:\n",
    "                    break\n",
    "                cpt += 1\n",
    "                frozen_comp = np.array(fc).reshape((dof_fc, self.size)).T\n",
    "                if dof > 0:\n",
    "                    for free_comp in subsets(poss_index, dof, repetition=True):\n",
    "                        free_comp_array = np.repeat(np.array([free_comp]), self.size, axis=0)\n",
    "                        coords = np.hstack((free_comp_array, frozen_comp))\n",
    "                        for perm in multiset_permutations(coords.T.tolist()):\n",
    "                            perm_coords = [list(i) for i in zip(*perm)]\n",
    "                            perm_coords.sort()\n",
    "                            coords_to_check.add(tuple(map(tuple, perm_coords)))\n",
    "                else:\n",
    "                    coords = frozen_comp\n",
    "                    for perm in multiset_permutations(coords.T.tolist()):\n",
    "                        perm_coords = [list(i) for i in zip(*perm)]\n",
    "                        perm_coords.sort()\n",
    "                        coords_to_check.add(tuple(map(tuple, perm_coords)))\n",
    "                        \n",
    "        for coords in coords_to_check:\n",
    "            total = 0\n",
    "            for tile in coords:\n",
    "                total += self.board[tile]\n",
    "            if abs(total) == self.size:\n",
    "                if total > 0:\n",
    "                    score_p1 += 1\n",
    "                else:\n",
    "                    score_p2 += 1\n",
    "                \n",
    "        return score_p1, score_p2\n",
    "    \n",
    "    def almost_align(self):\n",
    "        \n",
    "        def slice_to_mask(L):\n",
    "            \"\"\"\n",
    "            Enables to use slicing operator like array[x, y, :, z] with choosing the position\n",
    "            of the symbol ':' (represented with a -1 instead). For example L can be equal to\n",
    "            [0, 0, -1, 0] if we want to access self.board[0, 0, :, 0]\n",
    "            \"\"\"\n",
    "            mask = np.zeros([self.size] * self.n_dim, dtype=bool)\n",
    "            dim = L.index(-1)\n",
    "            for tile in range(self.size):\n",
    "                L[dim] = tile\n",
    "                mask[tuple(L)] = True\n",
    "            return mask\n",
    "        \n",
    "        score_p1 = 0\n",
    "        score_p2 = 0\n",
    "        # vertical and horizontal axis\n",
    "        all_axis = []\n",
    "        for d in range(self.size ** self.n_dim):\n",
    "            all_axis.append([(d // self.size**k) % self.size for k in range(self.n_dim)[::-1]])\n",
    "            # example in 3D case with size 3 :\n",
    "            # all_axis = [ [i, j, k] for i = 0, 1, 2 for j = 0, 1, 2 for k = 0, 1, 2 ]\n",
    "        for d in range(self.n_dim):\n",
    "            d_axis = np.array(all_axis)\n",
    "            d_axis[:, d] = -1\n",
    "            d_axis = np.unique(d_axis, axis=0)\n",
    "            for axis in d_axis:\n",
    "                space_mask = slice_to_mask(list(axis))\n",
    "                in_game_axis = self.board[space_mask]\n",
    "                axis_value = in_game_axis.sum().item()\n",
    "                if axis_value == self.size - 1:\n",
    "                    score_p1 += 1\n",
    "                elif axis_value == -self.size + 1:\n",
    "                    score_p2 += 1\n",
    "        \n",
    "        # diagonal axis\n",
    "        diag = np.array([range(self.size)]).T\n",
    "        antidiag = np.array([range(self.size-1, -1, -1)]).T\n",
    "        poss_diag = np.array([diag, antidiag])\n",
    "        poss_index = list(range(self.size))\n",
    "        coords_to_check = set()\n",
    "        for dof in range(self.n_dim-2, -1, -1):\n",
    "            dof_fc = self.n_dim - dof\n",
    "            cpt = 0\n",
    "            for fc in subsets(poss_diag, dof_fc, repetition=True):\n",
    "                if cpt == int(dof_fc / 2) + 1:\n",
    "                    break\n",
    "                cpt += 1\n",
    "                frozen_comp = np.array(fc).reshape((dof_fc, self.size)).T\n",
    "                if dof > 0:\n",
    "                    for free_comp in subsets(poss_index, dof, repetition=True):\n",
    "                        free_comp_array = np.repeat(np.array([free_comp]), self.size, axis=0)\n",
    "                        coords = np.hstack((free_comp_array, frozen_comp))\n",
    "                        for perm in multiset_permutations(coords.T.tolist()):\n",
    "                            perm_coords = [list(i) for i in zip(*perm)]\n",
    "                            perm_coords.sort()\n",
    "                            coords_to_check.add(tuple(map(tuple, perm_coords)))\n",
    "                else:\n",
    "                    coords = frozen_comp\n",
    "                    for perm in multiset_permutations(coords.T.tolist()):\n",
    "                        perm_coords = [list(i) for i in zip(*perm)]\n",
    "                        perm_coords.sort()\n",
    "                        coords_to_check.add(tuple(map(tuple, perm_coords)))\n",
    "                        \n",
    "        for coords in coords_to_check:\n",
    "            total = 0\n",
    "            for tile in coords:\n",
    "                total += self.board[tile]\n",
    "            if abs(total) == self.size - 1:\n",
    "                if total > 0:\n",
    "                    score_p1 += 1\n",
    "                else:\n",
    "                    score_p2 += 1\n",
    "                \n",
    "        return score_p1, score_p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "agent = Agent(size=3)\n",
    "random_agent = Agent(size=3, policy=advanced_random_policy)\n",
    "game = Game(agent, random_agent, n_dim=2, size=3)\n",
    "sarsa(game, agent, random_policy, alpha=0.8, alpha_factor=0.999, gamma=0.9, epsilon=1.0, epsilon_factor=0.999, \\\n",
    "      r_win=5.0, r_lose=0.0, r_even=1.0, r_even2=1.5, num_episodes=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent won 215 times, lost 121 times and did 664 even games\n"
     ]
    }
   ],
   "source": [
    "win_p1, winp2, tot_even = game.simulate_games(1000)\n",
    "print('Agent won', win_p1, 'times, lost', winp2, 'times and did', tot_even, 'even games')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "game.p1, game.p2 = game.p2, game.p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . \n",
      ". . . \n",
      ". . . \n",
      "\n",
      "Agent plays : (2, 0) \n",
      "\n",
      ". . . \n",
      ". . . \n",
      "X . . \n",
      "\n",
      "Agent plays : (1, 1) \n",
      "\n",
      ". . . \n",
      ". O . \n",
      "X . . \n",
      "\n",
      "Agent plays : (2, 2) \n",
      "\n",
      ". . . \n",
      ". O . \n",
      "X . X \n",
      "\n",
      "Agent plays : (2, 1) \n",
      "\n",
      ". . . \n",
      ". O . \n",
      "X O X \n",
      "\n",
      "Agent plays : (0, 1) \n",
      "\n",
      ". X . \n",
      ". O . \n",
      "X O X \n",
      "\n",
      "Agent plays : (0, 0) \n",
      "\n",
      "O X . \n",
      ". O . \n",
      "X O X \n",
      "\n",
      "Agent plays : (1, 2) \n",
      "\n",
      "O X . \n",
      ". O X \n",
      "X O X \n",
      "\n",
      "Agent plays : (0, 2) \n",
      "\n",
      "O X O \n",
      ". O X \n",
      "X O X \n",
      "\n",
      "Agent plays : (1, 0) \n",
      "\n",
      "O X O \n",
      "X O X \n",
      "X O X \n",
      "\n",
      "Game over. Score : (0, 0)\n",
      "Even score.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.play_a_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20])\n",
      "(3, 3)\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n",
      "O X X \n",
      "X O . \n",
      "X O O \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "grid_size = 3\n",
    "n_dim = 2\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, size=3, n_dim=2):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(size**n_dim,size**n_dim*2)\n",
    "        self.fc2 = torch.nn.Linear(size**n_dim*2, size**n_dim*2)\n",
    "        self.fc3 = torch.nn.Linear(size**n_dim*2, size**n_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.view(-1).type(torch.long)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.ReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.nn.ReLU()(x)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.nn.Softmax(dim=1)(x)\n",
    "        return x\n",
    "\n",
    "agent1 = Model() # randomly generate weight\n",
    "agent2 = Model()\n",
    "\n",
    "print(x.shape)\n",
    "game = Game(None, None)\n",
    "matches_result = []\n",
    "\n",
    "def get_best_possible(board, probs):\n",
    "    probs = [(probs[i], i) for i in range(probs.shape[0])]\n",
    "    probs = sorted(probs, reverse=True)\n",
    "    for j in probs:\n",
    "        position = j[1]\n",
    "        resulting_position = []\n",
    "        for k in range(n_dim):\n",
    "            resulting_position.append(position % grid_size)\n",
    "            position //= grid_size\n",
    "        resulting_position = tuple(resulting_position)\n",
    "        if board[resulting_position] == 0:\n",
    "            return resulting_position\n",
    "    return None\n",
    "\n",
    "def make_move(game, model):\n",
    "    prev_state = np.reshape(game.board, (1, -1))\n",
    "    state = torch.tensor(game.board).view(1, -1).type(torch.float)\n",
    "    result = model(state).detach().numpy()[0]\n",
    "    best_move = get_best_possible(game.board, result)\n",
    "    new_state, reward, is_done, _ = game.step(best_move)\n",
    "    return prev_state, reward, best_move, new_state\n",
    "    # return self.board, reward, self.is_done(), None\n",
    "\n",
    "\n",
    "game_records = []\n",
    "for i in range(100):\n",
    "    game.reset()\n",
    "    game_record = []\n",
    "    while not game.is_done():\n",
    "        result = make_move(game, agent1)\n",
    "        game_record.append(result)\n",
    "        if game.is_done():\n",
    "            break\n",
    "        result = make_move(game, agent2)\n",
    "        game_record.append(result)\n",
    "    game_records.append(game_record)\n",
    "    game.render()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RL_project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}